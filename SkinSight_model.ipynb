{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "188f5275",
      "metadata": {
        "id": "188f5275"
      },
      "source": [
        "# SkinSight AI: Skin Lesion Classification Model (Image-Only)\n",
        "\n",
        "This notebook implements a deep learning model for skin lesion classification using the ISIC dataset. The model uses only images and their corresponding diagnostic labels.\n",
        "\n",
        "**Modifications for Improved Performance:**\n",
        "- Enabled Mixed Precision Training for potential speed-up.\n",
        "- Implemented Class Weights to address dataset imbalance.\n",
        "- Enabled Fine-tuning of the pre-trained base model (EfficientNetB0).\n",
        "- Uses AdamW optimizer (from `tf.keras.optimizers`).\n",
        "- Added option for Custom Focal Loss.\n",
        "- Included `ReduceLROnPlateau` learning rate scheduler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9c475c0_pip",
      "metadata": {
        "id": "d9c475c0_pip"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow opencv-python pandas numpy matplotlib seaborn scikit-learn requests tqdm pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9c475c1_keras_upgrade",
      "metadata": {
        "id": "d9c475c1_keras_upgrade"
      },
      "outputs": [],
      "source": [
        "!pip install keras --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p data/images\n",
        "!mkdir -p data/metadata\n",
        "!mkdir -p models"
      ],
      "metadata": {
        "id": "sRryoNGKX6AP_mkdir"
      },
      "id": "sRryoNGKX6AP_mkdir",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9c475c2_wget_comments",
      "metadata": {
        "id": "d9c475c2_wget_comments"
      },
      "outputs": [],
      "source": [
        "# Assuming dataset is already downloaded. Provide download commands if needed.\n",
        "# Example:\n",
        "!wget https://isic-challenge-data.s3.amazonaws.com/2019/ISIC_2019_Training_Input.zip\n",
        "!wget https://isic-challenge-data.s3.amazonaws.com/2019/ISIC_2019_Training_Metadata.csv -O ./data/metadata/ISIC_2019_Training_Metadata.csv\n",
        "!wget https://isic-challenge-data.s3.amazonaws.com/2019/ISIC_2019_Training_GroundTruth.csv -O ./data/metadata/ISIC_2019_Training_GroundTruth.csv\n",
        "print(\"If you downloaded the zip, uncomment the next cell to unzip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9c475c3_unzip_comment",
      "metadata": {
        "id": "d9c475c3_unzip_comment"
      },
      "outputs": [],
      "source": [
        "!unzip -q ISIC_2019_Training_Input.zip -d ./data/images"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ca3575e_setup_title",
      "metadata": {
        "id": "3ca3575e_setup_title"
      },
      "source": [
        "## 1. Setup and Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d92846c_dependencies",
      "metadata": {
        "id": "9d92846c_dependencies"
      },
      "outputs": [],
      "source": [
        "# Basic data manipulation and visualization\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Image processing\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "# Deep learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, applications\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras import mixed_precision # For mixed precision training\n",
        "\n",
        "# Machine learning utilities\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder # Only for label mapping if needed, not features\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "from sklearn.utils import class_weight # For calculating class weights\n",
        "\n",
        "# Utilities\n",
        "import os\n",
        "import json\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Enable Mixed Precision Training (if using compatible GPU: NVIDIA Volta, Turing, Ampere or newer)\n",
        "policy = mixed_precision.Policy('mixed_float16')\n",
        "mixed_precision.set_global_policy(policy)\n",
        "print('Mixed precision policy:', mixed_precision.global_policy())\n",
        "\n",
        "# Custom Categorical Focal Loss Implementation\n",
        "class CategoricalFocalCrossentropy(tf.keras.losses.Loss):\n",
        "    def __init__(self, alpha=0.25, gamma=2.0, from_logits=False,\n",
        "                 name='categorical_focal_crossentropy', **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.from_logits = from_logits\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        if self.from_logits:\n",
        "            y_pred_softmax = tf.keras.activations.softmax(y_pred, axis=-1)\n",
        "        else:\n",
        "            y_pred_softmax = y_pred\n",
        "\n",
        "        epsilon = tf.keras.backend.epsilon()\n",
        "        y_pred_softmax = tf.clip_by_value(y_pred_softmax, epsilon, 1. - epsilon)\n",
        "\n",
        "        cross_entropy = -y_true * tf.math.log(y_pred_softmax)\n",
        "        focal_factor = tf.math.pow(1. - y_pred_softmax, self.gamma)\n",
        "        focal_loss = self.alpha * focal_factor * cross_entropy\n",
        "        focal_loss_summed = tf.reduce_sum(focal_loss, axis=-1)\n",
        "        return focal_loss_summed\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            'alpha': self.alpha,\n",
        "            'gamma': self.gamma,\n",
        "            'from_logits': self.from_logits\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b741d07_config_title",
      "metadata": {
        "id": "8b741d07_config_title"
      },
      "source": [
        "## 2. Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f09cb0e_config",
      "metadata": {
        "id": "8f09cb0e_config"
      },
      "outputs": [],
      "source": [
        "# Model Configuration\n",
        "CONFIG = {\n",
        "    # Image parameters\n",
        "    'IMG_SIZE': 224,\n",
        "    'BATCH_SIZE': 32,\n",
        "\n",
        "    # Training parameters\n",
        "    'EPOCHS': 50,\n",
        "    'FINETUNE_LEARNING_RATE': 1e-4,\n",
        "    'EARLY_STOPPING_PATIENCE': 10,\n",
        "    'REDUCE_LR_PATIENCE': 3,\n",
        "    'REDUCE_LR_FACTOR': 0.2,\n",
        "\n",
        "    # Model architecture\n",
        "    'BASE_MODEL': 'EfficientNetB0',\n",
        "    'DROPOUT_RATE': 0.4,\n",
        "    'N_LAYERS_TO_UNFREEZE': 30,\n",
        "\n",
        "    # Optimizer\n",
        "    'OPTIMIZER': 'AdamW', # 'Adam' or 'AdamW'\n",
        "    'WEIGHT_DECAY': 1e-5, # For AdamW\n",
        "\n",
        "    # Loss Function\n",
        "    'LOSS_FUNCTION': 'categorical_crossentropy', # 'categorical_crossentropy' or 'focal_loss'\n",
        "    'FOCAL_LOSS_ALPHA': 0.25,\n",
        "    'FOCAL_LOSS_GAMMA': 2.0,\n",
        "\n",
        "    # Class weights (will be calculated automatically)\n",
        "    'CLASS_WEIGHTS': None,\n",
        "\n",
        "    # Paths\n",
        "    'DATA_DIR': './data',\n",
        "    'IMAGE_SUBDIR': 'images/ISIC_2019_Training_Input',\n",
        "    'METADATA_SUBDIR': 'metadata',\n",
        "    'MODEL_SAVE_PATH': './models/skin_lesion_model_image_only_finetuned.h5',\n",
        "    'CHECKPOINT_DIR': './models/checkpoints'\n",
        "}\n",
        "os.makedirs(CONFIG['CHECKPOINT_DIR'], exist_ok=True)\n",
        "\n",
        "CLASSES = [\n",
        "    'melanoma',\n",
        "    'nevus',\n",
        "    'basal_cell_carcinoma',\n",
        "    'actinic_keratosis',\n",
        "    'benign_keratosis',\n",
        "    'dermatofibroma',\n",
        "    'vascular_lesions'\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9436fa26_load_meta_title",
      "metadata": {
        "id": "9436fa26_load_meta_title"
      },
      "source": [
        "## 3. Load ISIC Dataset (Metadata for Labels and Image Names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "download_functions_setup_dataset",
      "metadata": {
        "id": "download_functions_setup_dataset"
      },
      "outputs": [],
      "source": [
        "def load_isic_data_info():\n",
        "    \"\"\"Load ISIC dataset metadata and ground truth to get image names and labels.\"\"\"\n",
        "    metadata_path = os.path.join(CONFIG['DATA_DIR'], CONFIG['METADATA_SUBDIR'], 'ISIC_2019_Training_Metadata.csv')\n",
        "    ground_truth_path = os.path.join(CONFIG['DATA_DIR'], CONFIG['METADATA_SUBDIR'], 'ISIC_2019_Training_GroundTruth.csv')\n",
        "\n",
        "    if not os.path.exists(metadata_path) or not os.path.exists(ground_truth_path):\n",
        "        raise FileNotFoundError(\n",
        "            f\"Metadata ({metadata_path}) or ground truth ({ground_truth_path}) CSV files not found. \"\n",
        "            \"Please ensure they are downloaded and placed correctly.\"\n",
        "        )\n",
        "\n",
        "    metadata_df = pd.read_csv(metadata_path)\n",
        "    ground_truth_df = pd.read_csv(ground_truth_path)\n",
        "\n",
        "    # Ground truth has 'image' as name without extension, metadata has it too.\n",
        "    # We'll add '.jpg' to the 'image' column from ground_truth_df for consistency if merging.\n",
        "    # However, it's safer to merge and then form the .jpg name.\n",
        "\n",
        "    # Merge based on 'image' (which is the image name without extension)\n",
        "    # Only keep relevant columns from metadata_df if needed (e.g. if it had other info, but here it's mainly for linking)\n",
        "    combined_df = pd.merge(metadata_df[['image']], ground_truth_df, on='image', how='inner')\n",
        "\n",
        "    # Add .jpg extension to image names for file access\n",
        "    combined_df['image_filename'] = combined_df['image'].astype(str) + '.jpg'\n",
        "\n",
        "    class_mapping_from_gt_cols = {\n",
        "        'MEL': 'melanoma',\n",
        "        'NV': 'nevus',\n",
        "        'BCC': 'basal_cell_carcinoma',\n",
        "        'AK': 'actinic_keratosis',\n",
        "        'BKL': 'benign_keratosis',\n",
        "        'DF': 'dermatofibroma',\n",
        "        'VASC': 'vascular_lesions'\n",
        "    }\n",
        "\n",
        "    disease_cols_from_gt = list(class_mapping_from_gt_cols.keys())\n",
        "    present_disease_cols = [col for col in disease_cols_from_gt if col in combined_df.columns]\n",
        "\n",
        "    if not present_disease_cols:\n",
        "        raise ValueError(\"No target disease columns found in the combined data. Check CSV column names.\")\n",
        "\n",
        "    # Create 'diagnosis' column from one-hot encoded ground truth columns\n",
        "    # Get the column name (e.g., 'MEL', 'NV') where the value is 1\n",
        "    combined_df['diagnosis_short_code'] = combined_df[present_disease_cols].idxmax(axis=1)\n",
        "    combined_df['diagnosis'] = combined_df['diagnosis_short_code'].map(class_mapping_from_gt_cols)\n",
        "\n",
        "    # Filter out rows where diagnosis could not be determined from our target classes or if sum is not 1\n",
        "    combined_df = combined_df.dropna(subset=['diagnosis'])\n",
        "    combined_df = combined_df[combined_df[present_disease_cols].sum(axis=1) == 1]\n",
        "\n",
        "    # Select only the necessary columns: image filename and diagnosis\n",
        "    final_df = combined_df[['image_filename', 'diagnosis']].copy()\n",
        "    final_df.rename(columns={'image_filename': 'image'}, inplace=True) # Rename to 'image' for generators\n",
        "\n",
        "    print(\"\\nUnique diagnoses mapped:\", final_df['diagnosis'].unique())\n",
        "    print(\"Diagnosis value counts (from loaded and mapped data):\")\n",
        "    print(final_df['diagnosis'].value_counts())\n",
        "\n",
        "    return final_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74c9a357_datapreproc_title",
      "metadata": {
        "id": "74c9a357_datapreproc_title"
      },
      "source": [
        "## 4. Data Preprocessing (Splitting and Image Validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "preprocess_functions_simplified",
      "metadata": {
        "id": "preprocess_functions_simplified"
      },
      "outputs": [],
      "source": [
        "def create_data_generators():\n",
        "    \"\"\"Create data generators with augmentation for training.\"\"\"\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        preprocessing_function=applications.efficientnet.preprocess_input,\n",
        "        rotation_range=30,\n",
        "        width_shift_range=0.25,\n",
        "        height_shift_range=0.25,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        brightness_range=[0.8, 1.2],\n",
        "        channel_shift_range=20,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "    val_test_datagen = ImageDataGenerator(\n",
        "        preprocessing_function=applications.efficientnet.preprocess_input\n",
        "    )\n",
        "    return train_datagen, val_test_datagen\n",
        "\n",
        "def prepare_image_dataset_splits(df_images_labels):\n",
        "    \"\"\"Prepare the image dataset by validating images and creating train/val/test splits.\"\"\"\n",
        "    print('Preparing image dataset splits...')\n",
        "    df = df_images_labels.copy()\n",
        "\n",
        "    df['image'] = df['image'].astype(str)\n",
        "    base_image_path = os.path.join(CONFIG['DATA_DIR'], CONFIG['IMAGE_SUBDIR'])\n",
        "    df['full_image_path'] = df['image'].apply(lambda x: os.path.join(base_image_path, x))\n",
        "\n",
        "    print('Validating image files...')\n",
        "    valid_indices = []\n",
        "    for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Validating images\"):\n",
        "        if os.path.exists(row['full_image_path']):\n",
        "            try:\n",
        "                img = Image.open(row['full_image_path'])\n",
        "                img.verify()\n",
        "                # Check if image can be loaded by OpenCV (more robust check)\n",
        "                cv_img = cv2.imread(row['full_image_path'])\n",
        "                if cv_img is not None:\n",
        "                    valid_indices.append(index)\n",
        "                # else: print(f\"Warning: OpenCV could not read {row['full_image_path']}\")\n",
        "            except Exception as e:\n",
        "                # print(f'Warning: Corrupted image {row[\"full_image_path\"]}: {e}')\n",
        "                pass\n",
        "        # else: print(f\"Warning: Image file not found {row['full_image_path']}\")\n",
        "\n",
        "    df = df.loc[valid_indices].reset_index(drop=True)\n",
        "    df = df[['image', 'diagnosis']] # Keep only essential columns\n",
        "\n",
        "    print(f'\\nTotal images after validation: {len(df)}')\n",
        "    if len(df) == 0:\n",
        "        raise ValueError(\"No valid images found. Please check image paths and integrity.\")\n",
        "\n",
        "    train_df, temp_df = train_test_split(\n",
        "        df,\n",
        "        test_size=0.3,\n",
        "        stratify=df['diagnosis'],\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    val_df, test_df = train_test_split(\n",
        "        temp_df,\n",
        "        test_size=0.5,\n",
        "        stratify=temp_df['diagnosis'],\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    print(f\"Training samples: {len(train_df)}, Validation samples: {len(val_df)}, Test samples: {len(test_df)}\")\n",
        "    return train_df, val_df, test_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dataset_setup_title_exec",
      "metadata": {
        "id": "dataset_setup_title_exec"
      },
      "source": [
        "## 5. Dataset Info Loading Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dataset_setup_execution_load_info",
      "metadata": {
        "id": "dataset_setup_execution_load_info"
      },
      "outputs": [],
      "source": [
        "df_images_labels = None # Initialize\n",
        "try:\n",
        "    print('Loading ISIC dataset info (image names and labels)...')\n",
        "    df_images_labels = load_isic_data_info()\n",
        "    print(\"\\nOverall class distribution in the loaded and mapped dataset:\")\n",
        "    print(df_images_labels['diagnosis'].value_counts(normalize=True) * 100)\n",
        "except Exception as e:\n",
        "    print(f'Error loading dataset info: {str(e)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dataset_preparation_title_exec",
      "metadata": {
        "id": "dataset_preparation_title_exec"
      },
      "source": [
        "## 6. Dataset Splitting and Generator Creation Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dataset_preparation_execution_split_gen",
      "metadata": {
        "id": "dataset_preparation_execution_split_gen"
      },
      "outputs": [],
      "source": [
        "\n",
        "try:\n",
        "    train_df, val_df, test_df = prepare_image_dataset_splits(df_images_labels)\n",
        "\n",
        "    train_datagen, val_test_datagen = create_data_generators()\n",
        "    image_dir_path = os.path.join(CONFIG['DATA_DIR'], CONFIG['IMAGE_SUBDIR'])\n",
        "\n",
        "    train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe=train_df,\n",
        "        directory=image_dir_path,\n",
        "        x_col='image',\n",
        "        y_col='diagnosis',\n",
        "        target_size=(CONFIG['IMG_SIZE'], CONFIG['IMG_SIZE']),\n",
        "        batch_size=CONFIG['BATCH_SIZE'],\n",
        "        class_mode='categorical',\n",
        "        classes=CLASSES,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    val_generator = val_test_datagen.flow_from_dataframe(\n",
        "        dataframe=val_df,\n",
        "        directory=image_dir_path,\n",
        "        x_col='image',\n",
        "        y_col='diagnosis',\n",
        "        target_size=(CONFIG['IMG_SIZE'], CONFIG['IMG_SIZE']),\n",
        "        batch_size=CONFIG['BATCH_SIZE'],\n",
        "        class_mode='categorical',\n",
        "        classes=CLASSES,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    test_generator = val_test_datagen.flow_from_dataframe(\n",
        "        dataframe=test_df,\n",
        "        directory=image_dir_path,\n",
        "        x_col='image',\n",
        "        y_col='diagnosis',\n",
        "        target_size=(CONFIG['IMG_SIZE'], CONFIG['IMG_SIZE']),\n",
        "        batch_size=CONFIG['BATCH_SIZE'],\n",
        "        class_mode='categorical',\n",
        "        classes=CLASSES,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "except Exception as e:\n",
        "    print(f'Error preparing dataset splits or generators: {str(e)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dataset_statistics_title_viz",
      "metadata": {
        "id": "dataset_statistics_title_viz"
      },
      "source": [
        "## 7. Dataset Statistics and Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dataset_statistics_visualization_exec",
      "metadata": {
        "id": "dataset_statistics_visualization_exec"
      },
      "outputs": [],
      "source": [
        "\n",
        "print('\\nDataset Statistics (after splitting and validation):')\n",
        "total_validated_images = len(train_df) + len(val_df) + len(test_df)\n",
        "if total_validated_images > 0: # Avoid division by zero if all images were invalid\n",
        "  print(f'Training samples: {len(train_df)} ({len(train_df)/total_validated_images*100:.2f}%)')\n",
        "  print(f'Validation samples: {len(val_df)} ({len(val_df)/total_validated_images*100:.2f}%)')\n",
        "  print(f'Test samples: {len(test_df)} ({len(test_df)/total_validated_images*100:.2f}%)')\n",
        "else:\n",
        "  print(\"No validated images to show statistics for.\")\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.countplot(data=train_df, y='diagnosis', order=train_df['diagnosis'].value_counts().index, palette='viridis')\n",
        "plt.title('Class Distribution in Training Set')\n",
        "plt.xlabel('Number of Samples')\n",
        "plt.ylabel('Class')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sample_images_title_disp",
      "metadata": {
        "id": "sample_images_title_disp"
      },
      "source": [
        "## 8. Display Sample Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sample_images_display_exec",
      "metadata": {
        "id": "sample_images_display_exec"
      },
      "outputs": [],
      "source": [
        "\n",
        "try:\n",
        "    print('\\nDisplaying sample augmented images from training set:')\n",
        "    images, labels = next(train_generator)\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    for i in range(min(8, CONFIG['BATCH_SIZE'], len(images))):\n",
        "        plt.subplot(2, 4, i+1)\n",
        "        display_image = (images[i] * 0.5 + 0.5)\n",
        "        display_image = np.clip(display_image, 0, 1)\n",
        "        plt.imshow(display_image)\n",
        "        class_index = np.argmax(labels[i])\n",
        "        plt.title(f'Class: {CLASSES[class_index]}')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "except Exception as e:\n",
        "    print(f\"Could not display sample images: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "model_definition_title_imgonly",
      "metadata": {
        "id": "model_definition_title_imgonly"
      },
      "source": [
        "## 9. Model Definition (Image-Only with Fine-tuning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "model_definition_code_imgonly",
      "metadata": {
        "id": "model_definition_code_imgonly"
      },
      "outputs": [],
      "source": [
        "def build_model_image_only(num_classes, img_size, base_model_name, dropout_rate, n_layers_to_unfreeze):\n",
        "    image_input = layers.Input(shape=(img_size, img_size, 3), name='image_input', dtype=tf.float32)\n",
        "\n",
        "    if base_model_name == 'EfficientNetB0':\n",
        "        base_model_func = applications.EfficientNetB0\n",
        "    elif base_model_name == 'ResNet50':\n",
        "        base_model_func = applications.ResNet50\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported base model: {base_model_name}\")\n",
        "\n",
        "    base_model_instance = base_model_func(input_shape=(img_size, img_size, 3),\n",
        "                                        include_top=False,\n",
        "                                        weights='imagenet')\n",
        "\n",
        "    if n_layers_to_unfreeze > 0:\n",
        "        base_model_instance.trainable = True\n",
        "        print(f\"Unfreezing the top {n_layers_to_unfreeze} layers of {base_model_name}.\")\n",
        "        for layer in base_model_instance.layers[:-n_layers_to_unfreeze]:\n",
        "            layer.trainable = False\n",
        "        for layer in base_model_instance.layers: # Explicitly keep BN layers frozen during fine-tuning\n",
        "            if isinstance(layer, layers.BatchNormalization):\n",
        "                layer.trainable = False\n",
        "    else:\n",
        "        base_model_instance.trainable = False\n",
        "        print(f\"Keeping all layers of {base_model_name} frozen.\")\n",
        "\n",
        "    x = base_model_instance(image_input, training=(n_layers_to_unfreeze > 0 and base_model_instance.trainable))\n",
        "    x = layers.GlobalAveragePooling2D(name='global_avg_pool')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(dropout_rate)(x)\n",
        "    x = layers.Dense(128, activation='relu', name='dense_head_1')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(dropout_rate/2)(x)\n",
        "    output = layers.Dense(num_classes, activation='softmax', name='output', dtype='float32')(x)\n",
        "\n",
        "    model = models.Model(inputs=image_input, outputs=output)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "model_compilation_title_exec",
      "metadata": {
        "id": "model_compilation_title_exec"
      },
      "source": [
        "## 10. Model Compilation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "model_compilation_code_exec",
      "metadata": {
        "id": "model_compilation_code_exec"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"Building an image-only model with fine-tuning capabilities.\")\n",
        "model = build_model_image_only(\n",
        "    num_classes=len(CLASSES),\n",
        "    img_size=CONFIG['IMG_SIZE'],\n",
        "    base_model_name=CONFIG['BASE_MODEL'],\n",
        "    dropout_rate=CONFIG['DROPOUT_RATE'],\n",
        "    n_layers_to_unfreeze=CONFIG['N_LAYERS_TO_UNFREEZE']\n",
        ")\n",
        "\n",
        "if CONFIG['OPTIMIZER'] == 'AdamW':\n",
        "    optimizer = tf.keras.optimizers.AdamW(\n",
        "        learning_rate=CONFIG['FINETUNE_LEARNING_RATE'],\n",
        "        weight_decay=CONFIG['WEIGHT_DECAY']\n",
        "    )\n",
        "    print(f\"Using tf.keras.optimizers.AdamW with LR={CONFIG['FINETUNE_LEARNING_RATE']} and Weight Decay={CONFIG['WEIGHT_DECAY']}\")\n",
        "else:\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=CONFIG['FINETUNE_LEARNING_RATE'])\n",
        "    print(f\"Using Adam optimizer with LR={CONFIG['FINETUNE_LEARNING_RATE']}\")\n",
        "\n",
        "if CONFIG['LOSS_FUNCTION'] == 'focal_loss':\n",
        "    loss_fn = CategoricalFocalCrossentropy(\n",
        "        alpha=CONFIG['FOCAL_LOSS_ALPHA'],\n",
        "        gamma=CONFIG['FOCAL_LOSS_GAMMA'],\n",
        "        from_logits=False\n",
        "    )\n",
        "    print(f\"Using Custom Categorical Focal Loss with alpha={CONFIG['FOCAL_LOSS_ALPHA']}, gamma={CONFIG['FOCAL_LOSS_GAMMA']}\")\n",
        "else:\n",
        "    loss_fn = 'categorical_crossentropy'\n",
        "    print(f\"Using Categorical Crossentropy loss.\")\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss_fn,\n",
        "    metrics=[\n",
        "        'accuracy',\n",
        "        tf.keras.metrics.Precision(name='precision'),\n",
        "        tf.keras.metrics.Recall(name='recall'),\n",
        "        tf.keras.metrics.AUC(name='auc')\n",
        "    ]\n",
        ")\n",
        "model.summary()\n",
        "\n",
        "print(\"\\nTrainable status of base model layers (first 5 and last 5 after unfreezing logic):\")\n",
        "base_model_layer_name = CONFIG['BASE_MODEL'].lower() # e.g., 'efficientnetb0'\n",
        "# Keras might add a suffix like '_1' if model is rebuilt. Find robustly.\n",
        "actual_base_model_layer_name = None\n",
        "for layer in model.layers:\n",
        "    if base_model_layer_name in layer.name.lower() and isinstance(layer, tf.keras.Model):\n",
        "        actual_base_model_layer_name = layer.name\n",
        "        break\n",
        "if actual_base_model_layer_name:\n",
        "    base_model_from_model = model.get_layer(actual_base_model_layer_name)\n",
        "    for i, layer in enumerate(base_model_from_model.layers):\n",
        "        if i < 5 or i >= len(base_model_from_model.layers) - 5:\n",
        "            print(f\"Layer: {layer.name}, Trainable: {layer.trainable}\")\n",
        "else:\n",
        "    print(f\"Could not find base model layer containing: {base_model_layer_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "model_training_title_exec",
      "metadata": {
        "id": "model_training_title_exec"
      },
      "source": [
        "## 11. Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "model_training_code_exec",
      "metadata": {
        "id": "model_training_code_exec"
      },
      "outputs": [],
      "source": [
        "\n",
        "class_to_int_mapping = {classname: i for i, classname in enumerate(CLASSES)}\n",
        "train_labels_int_mapped = train_df['diagnosis'].map(class_to_int_mapping).values\n",
        "\n",
        "class_weights_calculated = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_labels_int_mapped),\n",
        "    y=train_labels_int_mapped\n",
        ")\n",
        "CONFIG['CLASS_WEIGHTS'] = dict(enumerate(class_weights_calculated))\n",
        "print(\"Calculated Class Weights:\", CONFIG['CLASS_WEIGHTS'])\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=CONFIG['EARLY_STOPPING_PATIENCE'],\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "model_checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=os.path.join(CONFIG['CHECKPOINT_DIR'], 'model_epoch_{epoch:02d}_valloss_{val_loss:.2f}.h5'),\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    mode='min',\n",
        "    verbose=1\n",
        ")\n",
        "reduce_lr_on_plateau = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=CONFIG['REDUCE_LR_FACTOR'],\n",
        "    patience=CONFIG['REDUCE_LR_PATIENCE'],\n",
        "    min_lr=1e-7,\n",
        "    verbose=1\n",
        ")\n",
        "callbacks_list = [early_stopping, model_checkpoint_callback, reduce_lr_on_plateau]\n",
        "\n",
        "print(\"\\nStarting model training...\")\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=CONFIG['EPOCHS'],\n",
        "    validation_data=val_generator,\n",
        "    callbacks=callbacks_list,\n",
        "    class_weight=CONFIG['CLASS_WEIGHTS'],\n",
        "    steps_per_epoch=max(1, train_generator.samples // CONFIG['BATCH_SIZE']), # Ensure at least 1 step\n",
        "    validation_steps=max(1, val_generator.samples // CONFIG['BATCH_SIZE'])\n",
        ")\n",
        "\n",
        "print(f\"\\nTraining finished. Saving final model to {CONFIG['MODEL_SAVE_PATH']}\")\n",
        "model.save(CONFIG['MODEL_SAVE_PATH'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "model_evaluation_title_exec",
      "metadata": {
        "id": "model_evaluation_title_exec"
      },
      "source": [
        "## 12. Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "model_evaluation_code_exec",
      "metadata": {
        "id": "model_evaluation_code_exec"
      },
      "outputs": [],
      "source": [
        "\n",
        "print('\\nPlotting training history...')\n",
        "# Plotting function\n",
        "def plot_history(training_history):\n",
        "    plt.figure(figsize=(14, 10))\n",
        "    metrics_to_plot = ['accuracy', 'loss', 'precision', 'recall', 'auc']\n",
        "    for i, metric in enumerate(metrics_to_plot):\n",
        "        plt.subplot(3, 2, i + 1)\n",
        "        if metric in training_history.history:\n",
        "            plt.plot(training_history.history[metric], label=f'Train {metric.capitalize()}')\n",
        "        if f'val_{metric}' in training_history.history:\n",
        "            plt.plot(training_history.history[f'val_{metric}'], label=f'Val {metric.capitalize()}')\n",
        "        plt.title(f'{metric.capitalize()} vs. Epochs')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel(metric.capitalize())\n",
        "        plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_history(history)\n",
        "\n",
        "print('\\nEvaluating model on test set...')\n",
        "test_generator.reset()\n",
        "eval_results = model.evaluate(test_generator,\n",
        "                              steps=max(1, test_generator.samples // CONFIG['BATCH_SIZE'] + (1 if test_generator.samples % CONFIG['BATCH_SIZE'] else 0)),\n",
        "                              verbose=1)\n",
        "metric_names = model.metrics_names\n",
        "for name, val in zip(metric_names, eval_results):\n",
        "    print(f\"Test {name}: {val:.4f}\")\n",
        "\n",
        "test_generator.reset()\n",
        "y_pred_probs = model.predict(test_generator,\n",
        "                              steps=max(1, test_generator.samples // CONFIG['BATCH_SIZE'] + (1 if test_generator.samples % CONFIG['BATCH_SIZE'] else 0)),\n",
        "                              verbose=1)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "y_true = test_generator.classes\n",
        "\n",
        "# Ensure y_pred from predict covers all samples in y_true from generator.classes\n",
        "# This is important if steps didn't perfectly align with total samples, though it should for predict.\n",
        "if len(y_pred) > len(y_true):\n",
        "    y_pred = y_pred[:len(y_true)]\n",
        "elif len(y_true) > len(y_pred): # This case should be less common if predict steps cover all data\n",
        "    y_true = y_true[:len(y_pred)]\n",
        "    y_pred_probs = y_pred_probs[:len(y_pred),:]\n",
        "\n",
        "print('\\nClassification Report:')\n",
        "print(classification_report(y_true, y_pred, target_names=CLASSES, zero_division=0))\n",
        "\n",
        "print('\\nConfusion Matrix:')\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=CLASSES, yticklabels=CLASSES)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "print('\\nROC Curves:')\n",
        "plt.figure(figsize=(12, 10))\n",
        "for i, class_name in enumerate(CLASSES):\n",
        "    y_true_binarized_for_class = (y_true == i).astype(int)\n",
        "    fpr, tpr, _ = roc_curve(y_true_binarized_for_class, y_pred_probs[:, i])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, lw=2, label=f'{class_name} (AUC = {roc_auc:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve for Each Class')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}